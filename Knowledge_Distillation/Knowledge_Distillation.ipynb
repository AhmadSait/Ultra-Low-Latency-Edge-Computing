{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569effbe-1946-4a6d-9387-76a954dec6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# ====================================================\n",
    "# Dataset Preparation: CIFAR-100\n",
    "# ====================================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7949a75-49eb-464a-a45b-6d4862d51194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature=4.0, alpha=0.5):\n",
    "        super(DistillationLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, student_logits, teacher_logits, labels):\n",
    "        # Soft loss\n",
    "        soft_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            torch.log_softmax(student_logits / self.temperature, dim=1),\n",
    "            torch.softmax(teacher_logits / self.temperature, dim=1)\n",
    "        )\n",
    "        # Hard loss\n",
    "        hard_loss = self.criterion_ce(student_logits, labels)\n",
    "        return self.alpha * soft_loss * (self.temperature ** 2) + (1.0 - self.alpha) * hard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dabb6464-dba6-414d-99e5-af7d4bb6b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when all layers are trained\n",
    "def train_kd_res_all(teacher_model, student_model, train_loader, epochs=10, lr=1e-3, temperature=4.0, alpha=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    teacher_model.to(device).eval()\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
    "    distillation_loss_fn = DistillationLoss(temperature, alpha)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model predictions (no gradient needed)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(images).logits\n",
    "\n",
    "            # Student model predictions\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "            # Update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b0123d9-3ba1-4edc-b9f4-4927822ec6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when all layers are trained\n",
    "def train_kd_net_all(teacher_model, student_model, train_loader, epochs=10, lr=1e-3, temperature=4.0, alpha=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    teacher_model.to(device).eval()\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
    "    distillation_loss_fn = DistillationLoss(temperature, alpha)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model predictions (no gradient needed)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(images)\n",
    "\n",
    "            # Student model predictions\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "            # Update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f468136a-4bca-430d-a089-c025d9dfe56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kd_res_classifier(teacher_model, student_model, train_loader, epochs=10, lr=1e-3, temperature=4.0, alpha=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    teacher_model.to(device).eval()\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    # ================================\n",
    "    # Freeze all layers except the classifier head\n",
    "    # ================================\n",
    "    for name, param in student_model.named_parameters():\n",
    "        if \"fc\" not in name and \"classifier\" not in name:  # Adjust for different models\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Use an optimizer that only updates trainable parameters\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, student_model.parameters()), lr=lr)\n",
    "    \n",
    "    distillation_loss_fn = DistillationLoss(temperature, alpha)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model predictions (no gradient needed)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(images).logits\n",
    "\n",
    "            # Student model predictions\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "            # Update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfe3d9b8-ac34-42b4-a12a-37ed641043e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kd_net_classifier(teacher_model, student_model, train_loader, epochs=10, lr=1e-3, temperature=4.0, alpha=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    teacher_model.to(device).eval()\n",
    "    student_model.to(device).train()\n",
    "\n",
    "    # ================================\n",
    "    # Freeze all layers except the classifier head\n",
    "    # ================================\n",
    "    for name, param in student_model.named_parameters():\n",
    "        if \"fc\" not in name and \"classifier\" not in name:  # Adjust for different models\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Use an optimizer that only updates trainable parameters\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, student_model.parameters()), lr=lr)\n",
    "    \n",
    "    distillation_loss_fn = DistillationLoss(temperature, alpha)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Teacher model predictions (no gradient needed)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher_model(images)\n",
    "\n",
    "            # Student model predictions\n",
    "            student_logits = student_model(images)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = distillation_loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "            # Update optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(student_logits, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0751c3f-2d5b-461a-a502-8962621bb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device).eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(probs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe9bcd3-95bd-49ce-be57-058f6ebff104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, torch, torch.nn as nn\n",
    "\n",
    "def evaluate_model_performance_res(model, test_loader, baseline_accuracy=75.00, baseline_inference_time=0.10, baseline_model_size=100.0):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device).eval()\n",
    "    criterion, total, correct, running_loss, inference_times = nn.CrossEntropyLoss(), 0, 0, 0.0, []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            start_time = time.time(); outputs = model(images); end_time = time.time()\n",
    "            inference_times.append(end_time - start_time)\n",
    "            running_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1); total += labels.size(0); correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy, avg_loss, avg_inference_time = 100 * correct / total, running_loss / len(test_loader), sum(inference_times) / len(inference_times)\n",
    "    model_size = os.path.getsize(\"temp.pth\") / (1024 * 1024) if torch.save(model.state_dict(), \"temp.pth\") or os.path.exists(\"temp.pth\") else 0; os.remove(\"temp.pth\")\n",
    "    accuracy_drop, speed_improvement, size_reduction = baseline_accuracy - accuracy, (baseline_inference_time - avg_inference_time) / baseline_inference_time * 100, (baseline_model_size - model_size) / baseline_model_size * 100\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}%, Average Loss: {avg_loss}, Model Size: {model_size} MB, Average Inference Time: {avg_inference_time}s\\nPerformance Comparison:\\nAccuracy Drop: {accuracy_drop}%, Speed Improvement: {speed_improvement}%, Size Reduction: {size_reduction}%\")\n",
    "    return accuracy, avg_loss, avg_inference_time, model_size\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model_performance_mobile(model, test_loader, baseline_accuracy=71.00, baseline_inference_time=0.05, baseline_model_size=20.0):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device).eval()\n",
    "    criterion, total, correct, running_loss, inference_times = nn.CrossEntropyLoss(), 0, 0, 0.0, []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            start_time = time.time(); outputs = model(images); end_time = time.time()\n",
    "            inference_times.append(end_time - start_time)\n",
    "            running_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1); total += labels.size(0); correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy, avg_loss, avg_inference_time = 100 * correct / total, running_loss / len(test_loader), sum(inference_times) / len(inference_times)\n",
    "    model_size = os.path.getsize(\"temp.pth\") / (1024 * 1024) if torch.save(model.state_dict(), \"temp.pth\") or os.path.exists(\"temp.pth\") else 0; os.remove(\"temp.pth\")\n",
    "    accuracy_drop, speed_improvement, size_reduction = baseline_accuracy - accuracy, (baseline_inference_time - avg_inference_time) / baseline_inference_time * 100, (baseline_model_size - model_size) / baseline_model_size * 100\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}%, Average Loss: {avg_loss}, Model Size: {model_size} MB, Average Inference Time: {avg_inference_time}s\\nPerformance Comparison:\\nAccuracy Drop: {accuracy_drop}%, Speed Improvement: {speed_improvement}%, Size Reduction: {size_reduction}%\")\n",
    "    return accuracy, avg_loss, avg_inference_time, model_size\n",
    "\n",
    "def save_model(model, save_path):\n",
    "    \"\"\"Save the model's state dictionary to the specified path.\"\"\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'Model saved to {save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22187546-f52a-47ed-8a63-42cdcff734b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 20:17:30.161088: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-17 20:17:32.010005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737134252.580133 3796820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737134252.761396 3796820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-17 20:17:34.362836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/saitaa0b/miniconda3/envs/CS294Y/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.8602, Accuracy: 62.84%\n",
      "Epoch [2/5], Loss: 0.8469, Accuracy: 80.40%\n",
      "Epoch [3/5], Loss: 0.6383, Accuracy: 85.92%\n",
      "Epoch [4/5], Loss: 0.5176, Accuracy: 89.77%\n",
      "Epoch [5/5], Loss: 0.4412, Accuracy: 92.25%\n",
      "Test Accuracy: 80.16%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Teacher Model: Aznaur's ResNet-50\n",
    "# ====================================================\n",
    "model_name = \"jialicheng/cifar100-resnet-50\"\n",
    "teacher_model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "# ====================================================\n",
    "# Student Model: ResNet-18\n",
    "# ====================================================\n",
    "student_model = models.resnet18(pretrained=True)\n",
    "student_model.fc = nn.Linear(student_model.fc.in_features, 100)  # Adjust for CIFAR-100\n",
    "student_model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_kd_res_all(teacher_model, student_model, train_loader, epochs=5, lr=3e-4, temperature=4.0, alpha=0.5)\n",
    "    evaluate(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e427dfa8-ec6f-4eb3-94ae-02073d95c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.09%, Average Loss: 0.6681001088287257, Model Size: 42.899356842041016 MB, Average Inference Time: 0.002709077883370315s\n",
      "Performance Comparison:\n",
      "Accuracy Drop: -5.090000000000003%, Speed Improvement: 97.29092211662969%, Size Reduction: 57.100643157958984%\n"
     ]
    }
   ],
   "source": [
    "accuracy, avg_loss, avg_inference_time, model_size = evaluate_model_performance_res(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58274ca4-8485-4777-91ad-e310bb1cacc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Student_Models/cifar100_resnet18.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"Student_Models/cifar100_resnet18.pth\" \n",
    "save_model(student_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff8a5f3f-b615-432d-ab0d-e2e223fdc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.4741, Accuracy: 57.79%\n",
      "Epoch [2/5], Loss: 0.9509, Accuracy: 80.96%\n",
      "Epoch [3/5], Loss: 0.8037, Accuracy: 88.11%\n",
      "Epoch [4/5], Loss: 0.7146, Accuracy: 92.43%\n",
      "Epoch [5/5], Loss: 0.6546, Accuracy: 95.14%\n",
      "Test Accuracy: 81.85%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Teacher Model: EfficientNet B5 (from timm)\n",
    "# ====================================================\n",
    "teacher_model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=100)\n",
    "teacher_model.eval()\n",
    "\n",
    "# ====================================================\n",
    "# Student Model: EfficientNet-Lite0 (from timm)\n",
    "# ====================================================\n",
    "student_model = timm.create_model('efficientnet_lite0', pretrained=True, num_classes=100)\n",
    "student_model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_kd_net_all(teacher_model, student_model, train_loader, epochs=5, lr=3e-4, temperature=4.0, alpha=0.5)\n",
    "    evaluate(student_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26de2b50-bb46-4f47-97ad-625f0b65f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.76%, Average Loss: 0.8752514659603939, Model Size: 13.591398239135742 MB, Average Inference Time: 0.005031636998623233s\n",
      "Performance Comparison:\n",
      "Accuracy Drop: -10.760000000000005%, Speed Improvement: 89.93672600275355%, Size Reduction: 32.04300880432129%\n"
     ]
    }
   ],
   "source": [
    "accuracy, avg_loss, avg_inference_time, model_size = evaluate_model_performance_net(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cc8f201-330a-47ad-a201-37a7688d0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Student_Models/cifar100_efficientnet_lite0.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"Student_Models/cifar100_efficientnet_lite0.pth\" \n",
    "save_model(student_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aaaef55f-a8a6-4a5d-9563-74678bc00870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.3664, Accuracy: 63.06%\n",
      "Epoch [2/5], Loss: 0.9022, Accuracy: 83.13%\n",
      "Epoch [3/5], Loss: 0.7662, Accuracy: 89.25%\n",
      "Epoch [4/5], Loss: 0.6856, Accuracy: 93.01%\n",
      "Epoch [5/5], Loss: 0.6274, Accuracy: 95.65%\n",
      "Test Accuracy: 82.79%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Teacher Model: EfficientNet-B5 (from timm)\n",
    "# ====================================================\n",
    "teacher_model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=100)\n",
    "teacher_model.eval()\n",
    "\n",
    "# ====================================================\n",
    "# Student Model: MobileNetV3-Large (from timm)\n",
    "# ====================================================\n",
    "student_model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=100)\n",
    "student_model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_kd_net_all(teacher_model, student_model, train_loader, epochs=5, lr=3e-4, temperature=4.0, alpha=0.5)\n",
    "    evaluate(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d04e19e-ea13-470e-ad11-d24351156f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.75%, Average Loss: 0.8692005895361116, Model Size: 16.70149040222168 MB, Average Inference Time: 0.006251126905030842s\n",
      "Performance Comparison:\n",
      "Accuracy Drop: -11.75%, Speed Improvement: 87.49774618993831%, Size Reduction: 16.4925479888916%\n"
     ]
    }
   ],
   "source": [
    "accuracy, avg_loss, avg_inference_time, model_size = evaluate_model_performance_mobile(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81b3bdad-cc6b-468c-94d2-7478bdc8050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Student_Models/cifar100_mobilenetv3_large_100_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model after testing\n",
    "save_path = \"Student_Models/cifar100_mobilenetv3_large_100_model.pth\" \n",
    "save_model(student_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56bf0bc5-28da-4ab7-a690-255f3108e519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.5223, Accuracy: 54.60%\n",
      "Epoch [2/5], Loss: 1.0790, Accuracy: 73.98%\n",
      "Epoch [3/5], Loss: 0.9515, Accuracy: 79.60%\n",
      "Epoch [4/5], Loss: 0.8751, Accuracy: 83.32%\n",
      "Epoch [5/5], Loss: 0.8178, Accuracy: 86.11%\n",
      "Test Accuracy: 72.97%\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Teacher Model: EfficientNet-B5 (from timm)\n",
    "# ====================================================\n",
    "teacher_model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=100)\n",
    "teacher_model.eval()\n",
    "\n",
    "# ====================================================\n",
    "# Student Model: MobileNetV3-Small (from timm)\n",
    "# ====================================================\n",
    "student_model = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=100)\n",
    "student_model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_kd_net_all(teacher_model, student_model, train_loader, epochs=5, lr=3e-4, temperature=4.0, alpha=0.5)\n",
    "    evaluate(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ecc33f4-9b92-449c-9fc4-40c300bee103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.93%, Average Loss: 1.2232606161998798, Model Size: 6.297517776489258 MB, Average Inference Time: 0.005306020567688761s\n",
      "Performance Comparison:\n",
      "Accuracy Drop: -1.9300000000000068%, Speed Improvement: 89.38795886462249%, Size Reduction: 68.51241111755371%\n"
     ]
    }
   ],
   "source": [
    "accuracy, avg_loss, avg_inference_time, model_size = evaluate_model_performance_mobile(student_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06ee1923-15c0-4257-883f-d3a36dd981f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Student_Models/cifar100_mobilenetv3_small_100.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"Student_Models/cifar100_mobilenetv3_small_100.pth\" \n",
    "save_model(student_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a2f9974-f253-40a8-a517-d5c313795528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3802634/1191152867.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_small model has been converted to ONNX (FP16) and saved at Student_Models/efficientnet_b5.onnx\n",
      "ONNX model is valid!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-01-21 20:51:36.577962875 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851133, index: 0, mask: {1, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.578049730 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851137, index: 4, mask: {5, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.578075988 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851135, index: 2, mask: {3, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.578076900 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851134, index: 1, mask: {2, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.578106244 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851139, index: 6, mask: {7, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.578104362 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851136, index: 3, mask: {4, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.579315319 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851150, index: 17, mask: {18, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.586640349 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851151, index: 18, mask: {19, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.586649997 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851156, index: 23, mask: {24, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.586665886 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851159, index: 26, mask: {27, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.587656483 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851168, index: 35, mask: {36, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.586647005 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851155, index: 22, mask: {23, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.590620002 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851154, index: 21, mask: {22, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.591615858 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851152, index: 19, mask: {20, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.591624377 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851171, index: 38, mask: {39, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.594612075 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851153, index: 20, mask: {21, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.594620448 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851160, index: 27, mask: {28, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.595618972 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851172, index: 39, mask: {40, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.598621619 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851161, index: 28, mask: {29, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.598642369 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851158, index: 25, mask: {26, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.599618887 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851173, index: 40, mask: {41, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.598622165 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851157, index: 24, mask: {25, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.606647880 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851169, index: 36, mask: {37, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.607618962 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851144, index: 11, mask: {12, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.610647455 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851141, index: 8, mask: {9, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.611628460 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851170, index: 37, mask: {38, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.614622906 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851143, index: 10, mask: {11, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.614652234 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851174, index: 41, mask: {42, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.615620316 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851145, index: 12, mask: {13, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.616629022 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851177, index: 44, mask: {45, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.618622458 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851175, index: 42, mask: {43, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.619622923 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851146, index: 13, mask: {14, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.621622974 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851178, index: 45, mask: {46, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.622624966 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851176, index: 43, mask: {44, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.622656132 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851149, index: 16, mask: {17, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.622656221 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851140, index: 7, mask: {8, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.626626725 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851138, index: 5, mask: {6, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.626651197 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851142, index: 9, mask: {10, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.626630867 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851179, index: 46, mask: {47, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.630631072 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851147, index: 14, mask: {15, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n",
      "\u001b[1;31m2025-01-21 20:51:36.631623417 [E:onnxruntime:Default, env.cc:234 ThreadMain] pthread_setaffinity_np failed for thread: 3851148, index: 15, mask: {16, }, error code: 22 error msg: Invalid argument. Specify the number of threads explicitly so the affinity is not set.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference with ONNX Runtime (FP16) completed successfully!\n",
      "ONNX FP16 output matches PyTorch FP16 output!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#converting models to ONNX for Edge Impulse\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# TODO: Step 1: Load the mobilenet Model\n",
    "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=100)\n",
    "model_path = \"Student_Models/efficientnet_b5.pth\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Convert Model to FP16\n",
    "# Move model to half precision (FP16)\n",
    "# model.half()\n",
    "\n",
    "# Step 3: Create a Dummy Input in FP16\n",
    "# mobilenetv3_small expects an input of shape [batch_size, 3, 32, 32]\n",
    "dummy_input = torch.randn(1, 3, 32, 32, dtype=torch.float32).to(device)\n",
    "\n",
    "# TODO: Step 4: Export the Model to ONNX in FP16\n",
    "onnx_path = \"Student_Models/efficientnet_b5.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(f\"mobilenetv3_small model has been converted to ONNX (FP16) and saved at {onnx_path}\")\n",
    "\n",
    "# Step 5: Verify the ONNX Model\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid!\")\n",
    "\n",
    "# Step 6: Run Inference with ONNX Runtime in FP16\n",
    "# Initialize ONNX Runtime session with FP16 precision\n",
    "ort_session = ort.InferenceSession(onnx_path, providers=['CUDAExecutionProvider'])\n",
    "\n",
    "# Convert the dummy input to NumPy (FP16)\n",
    "dummy_input_np = dummy_input.cpu().numpy()  # Move to CPU and convert to NumPy array\n",
    "\n",
    "# Run inference using ONNX Runtime\n",
    "ort_inputs = {'input': dummy_input_np}  # Input dictionary for ONNX runtime\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(\"Inference with ONNX Runtime (FP16) completed successfully!\")\n",
    "\n",
    "# Step 7: Compare ONNX Output with PyTorch Output\n",
    "# Run inference on the PyTorch model\n",
    "with torch.no_grad():\n",
    "    torch_out = model(dummy_input)  # Keep the input on the same device as the model\n",
    "\n",
    "# Convert PyTorch output to NumPy for comparison\n",
    "torch_out_np = torch_out.cpu().numpy()  # Move to CPU and convert to NumPy array\n",
    "\n",
    "# Compare outputs\n",
    "if np.allclose(torch_out_np, ort_outs[0], atol=1e-2):  # Adjust tolerance for FP16\n",
    "    print(\"ONNX FP16 output matches PyTorch FP16 output!\")\n",
    "else:\n",
    "    print(\"ONNX FP16 output does not match PyTorch FP16 output. Check for potential issues.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b2ee7-1c3f-44bc-902f-e0face781081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
