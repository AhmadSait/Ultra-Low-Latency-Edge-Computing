{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvs3d3QGqNc-",
        "outputId": "23f974f0-1e15-4ade-b529-7c5fd9d83e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17265, done.\u001b[K\n",
            "remote: Counting objects: 100% (186/186), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 17265 (delta 107), reused 60 (delta 60), pack-reused 17079 (from 2)\u001b[K\n",
            "Receiving objects: 100% (17265/17265), 15.92 MiB | 11.24 MiB/s, done.\n",
            "Resolving deltas: 100% (11808/11808), done.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.65-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading ultralytics-8.3.65-py3-none-any.whl (911 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m911.6/911.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.65 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "# Install yolov5 dependencies\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!cd yolov5 && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to yolov5 folder\n",
        "%cd /content/yolov5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8yPfX51qP9-",
        "outputId": "9ed8709e-4cd3-44f5-bf8c-c132bcc21563"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install sparseML\n",
        "pip install \"sparseml[yolov5]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mz6ZI5mWqWBr",
        "outputId": "64cf6cc1-2130-49e2-945f-ec7e3367785f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sparseml[yolov5]\n",
            "  Downloading sparseml-1.8.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting sparsezoo>=1.7.0 (from sparseml[yolov5])\n",
            "  Downloading sparsezoo-1.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (3.10.0)\n",
            "Collecting merge-args>=0.1.0 (from sparseml[yolov5])\n",
            "  Downloading merge_args-0.1.5-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting onnx<1.15.0,>=1.5.0 (from sparseml[yolov5])\n",
            "  Downloading onnx-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (2.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (24.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (5.9.5)\n",
            "Collecting pydantic<2.8.0,>=2.0.0 (from sparseml[yolov5])\n",
            "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (1.6.0)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (4.67.1)\n",
            "Collecting toposort>=1.0 (from sparseml[yolov5])\n",
            "  Downloading toposort-1.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting GPUtil>=1.4.0 (from sparseml[yolov5])\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf<=3.20.3,>=3.12.2 (from sparseml[yolov5])\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (8.1.8)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from sparseml[yolov5]) (2.5.1+cu121)\n",
            "Collecting gputils (from sparseml[yolov5])\n",
            "  Downloading gputils-1.0.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting torchvision<0.17,>=0.3.0 (from sparseml[yolov5])\n",
            "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting opencv-python<=4.6.0.66 (from sparseml[yolov5])\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting nm-yolov5<=1.8.0 (from sparseml[yolov5])\n",
            "  Downloading nm_yolov5-1.7.0.60200-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->sparseml[yolov5]) (2.8.2)\n",
            "Collecting pillow>=8 (from matplotlib>=3.0.0->sparseml[yolov5])\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nm-yolov5<=1.8.0->sparseml[yolov5]) (2.17.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from nm-yolov5<=1.8.0->sparseml[yolov5]) (0.13.2)\n",
            "Requirement already satisfied: ipython<=8.12 in /usr/local/lib/python3.11/dist-packages (from nm-yolov5<=1.8.0->sparseml[yolov5]) (7.34.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from nm-yolov5<=1.8.0->sparseml[yolov5]) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.11/dist-packages (from onnx<1.15.0,>=1.5.0->sparseml[yolov5]) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.0->sparseml[yolov5]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25.0->sparseml[yolov5]) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.8.0,>=2.0.0->sparseml[yolov5]) (0.7.0)\n",
            "Collecting pydantic-core==2.18.4 (from pydantic<2.8.0,>=2.0.0->sparseml[yolov5])\n",
            "  Downloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->sparseml[yolov5]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->sparseml[yolov5]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->sparseml[yolov5]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->sparseml[yolov5]) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->sparseml[yolov5]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.2->sparseml[yolov5]) (3.5.0)\n",
            "Collecting py-machineid>=0.3.0 (from sparsezoo>=1.7.0->sparseml[yolov5])\n",
            "  Downloading py_machineid-0.7.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: geocoder>=1.38.0 in /usr/local/lib/python3.11/dist-packages (from sparsezoo>=1.7.0->sparseml[yolov5]) (1.38.1)\n",
            "Collecting onnxruntime>=1.0.0 (from sparsezoo>=1.7.0->sparseml[yolov5])\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->sparseml[yolov5]) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->sparseml[yolov5]) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->sparseml[yolov5]) (1.3.0)\n",
            "Collecting torch>=1.7.0 (from sparseml[yolov5])\n",
            "  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->sparseml[yolov5])\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.7.0->sparseml[yolov5])\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting triton==2.1.0 (from torch>=1.7.0->sparseml[yolov5])\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[yolov5]) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.11/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[yolov5]) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geocoder>=1.38.0->sparsezoo>=1.7.0->sparseml[yolov5]) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5])\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (4.9.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[yolov5])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[yolov5]) (24.12.23)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->nm-yolov5<=1.8.0->sparseml[yolov5]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->nm-yolov5<=1.8.0->sparseml[yolov5]) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->nm-yolov5<=1.8.0->sparseml[yolov5]) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->nm-yolov5<=1.8.0->sparseml[yolov5]) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->sparseml[yolov5]) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<=8.12->nm-yolov5<=1.8.0->sparseml[yolov5]) (0.2.13)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.0.0->sparsezoo>=1.7.0->sparseml[yolov5])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading merge_args-0.1.5-py2.py3-none-any.whl (6.0 kB)\n",
            "Downloading nm_yolov5-1.7.0.60200-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sparsezoo-1.8.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gputils-1.0.6-py3-none-any.whl (3.8 kB)\n",
            "Downloading sparseml-1.8.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_machineid-0.7.0-py3-none-any.whl (4.9 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=8670e993a5ad8a45b5a04493e4554a36ad03cec1e3b792bafb58ef4e272e0043\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: toposort, py-machineid, merge-args, GPUtil, triton, pydantic-core, protobuf, pillow, opencv-python, nvidia-nccl-cu12, nvidia-cudnn-cu12, jedi, humanfriendly, pydantic, onnx, coloredlogs, torch, onnxruntime, gputils, torchvision, sparsezoo, sparseml, nm-yolov5\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.5\n",
            "    Uninstalling pydantic-2.10.5:\n",
            "      Successfully uninstalled pydantic-2.10.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "scikit-image 0.25.0 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.2 which is incompatible.\n",
            "google-genai 0.3.0 requires pillow<12.0.0,>=10.0.0, but you have pillow 9.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GPUtil-1.4.0 coloredlogs-15.0.1 gputils-1.0.6 humanfriendly-10.0 jedi-0.19.2 merge-args-0.1.5 nm-yolov5-1.7.0.60200 nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.18.1 onnx-1.14.1 onnxruntime-1.20.1 opencv-python-4.6.0.66 pillow-9.5.0 protobuf-3.20.3 py-machineid-0.7.0 pydantic-2.7.4 pydantic-core-2.18.4 sparseml-1.8.0 sparsezoo-1.8.1 toposort-1.10 torch-2.1.2 torchvision-0.16.2 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google"
                ]
              },
              "id": "18c73333bad843dba1fb5f7bcd3fbffb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for yolov5s 75% pruning, quantization, and layer wise knowledge distillation with yolov5-l\n",
        "!sparseml.yolov5.train \\\n",
        "  --weights yolov5s.pt \\\n",
        "  --recipe zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none \\\n",
        "  --teacher-weights zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/base-none \\\n",
        "  --data coco128.yaml \\\n",
        "  --hyp hyps/hyp.scratch-low.yaml --cfg yolov5s.yaml --patience 0 --gradient-accum-steps 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8wRR5HSQqDP",
        "outputId": "785b1ede-1589-48e5-ce23-f21e21e901f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-18 21:17:14.902374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-18 21:17:15.239914: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-18 21:17:15.333200: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-18 21:17:15.881008: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-18 21:17:18.540034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, teacher_weights=zoo:cv/detection/yolov5-x/pytorch/ultralytics/coco/base-none, data=coco128.yaml, data_path=, hyp=hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, gradient_accum_steps=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/yolov5/yolov5_runs/train, log_dir=None, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=0, freeze=[0], save_period=-1, seed=0, local_rank=-1, recipe=zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none, recipe_args=None, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2025-1-18 Python-3.11.11 torch-2.1.2+cu121 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov5/yolov5_runs/train', view at http://localhost:6006/\n",
            "\n",
            "Dataset not found ⚠️, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 104MB/s]\n",
            "Dataset download success ✅ (1.2s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 18.3MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 97.8MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Downloading Chunks for recipe.md: 100% 7.62k/7.62k [00:00<00:00, 25.7kB/s]\n",
            "Combining Chunks: 100% 7.62k/7.62k [00:00<00:00, 5.58MB/s]\n",
            "Transferred 348/349 items from yolov5s.pt\n",
            "Downloading Chunks for model.pt: 100% 174M/174M [00:03<00:00, 45.0MB/s]\n",
            "Combining Chunks: 100% 174M/174M [00:00<00:00, 288MB/s]\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 567 layers, 86749405 parameters, 0 gradients, 206.3 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<00:00, 1395.17it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/yolov5/yolov5_runs/train/exp/labels.jpg... \n",
            "2025-01-18 21:18:07 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/18-01-2025_21.18.07.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/18-01-2025_21.18.07.log\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mSparse training detected. Wrapping training process with SparseML\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mDisabling LR scheduler, managing LR using SparseML recipe\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOverriding total number of training epochs with value from recipe: 110\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov5/yolov5_runs/train/exp\u001b[0m\n",
            "Starting training for 110 epochs...\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/109         0G     0.0452    0.06464    0.01802        194        640: 100% 8/8 [04:14<00:00, 31.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [01:18<00:00, 19.61s/it]\n",
            "                   all        128        929      0.698      0.611      0.688      0.455\n",
            "Adjusted gradient clipping threshold to 2.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/109         0G    0.04508    0.06193    0.01185        196        640:  12% 1/8 [00:40<04:45, 40.84s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/sparseml.yolov5.train\", line 8, in <module>\n",
            "    sys.exit(train())\n",
            "             ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sparseml/yolov5/scripts.py\", line 41, in train\n",
            "    train_run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/train.py\", line 732, in run\n",
            "    main(opt)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/train.py\", line 632, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/train.py\", line 376, in train\n",
            "    pred = model(imgs)  # forward\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "        ^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/models/common.py\", line 234, in forward\n",
            "    return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/yolov5/models/common.py\", line 57, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "                            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for yolov5s 75% pruning, quantization, and layer wise knowledge distillation with yolov5-x\n",
        "!sparseml.yolov5.train \\\n",
        "  --weights zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/base-none \\\n",
        "  --recipe zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none \\\n",
        "  --teacher-weights zoo:cv/detection/yolov5-x/pytorch/ultralytics/coco/base-none \\\n",
        "  --data coco128.yaml \\\n",
        "  --hyp hyps/hyp.scratch-low.yaml --cfg yolov5s.yaml --patience 0 --gradient-accum-steps 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7imuZwIvqdnh",
        "outputId": "9dc7fad5-e255-4f5e-9dec-d1879a6fd9bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-18 20:07:44.209417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-18 20:07:44.229844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-18 20:07:44.236174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-18 20:07:44.250949: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-18 20:07:45.626817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/base-none, cfg=yolov5s.yaml, teacher_weights=zoo:cv/detection/yolov5-x/pytorch/ultralytics/coco/base-none, data=coco128.yaml, data_path=, hyp=hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, gradient_accum_steps=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/yolov5/yolov5_runs/train, log_dir=None, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=0, freeze=[0], save_period=-1, seed=0, local_rank=-1, recipe=zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none, recipe_args=None, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2025-1-18 Python-3.11.11 torch-2.1.2+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov5/yolov5_runs/train', view at http://localhost:6006/\n",
            "\n",
            "Dataset not found ⚠️, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 75.3MB/s]\n",
            "Dataset download success ✅ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 13.8MB/s]\n",
            "Downloading Chunks for model.pt: 100% 14.8M/14.8M [00:00<00:00, 20.2MB/s]\n",
            "Combining Chunks: 100% 14.8M/14.8M [00:00<00:00, 630MB/s]\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "Downloading Chunks for recipe.md: 100% 7.62k/7.62k [00:00<00:00, 23.3kB/s]\n",
            "Combining Chunks: 100% 7.62k/7.62k [00:00<00:00, 8.86MB/s]\n",
            "Transferred 348/349 items from /root/.cache/sparsezoo/neuralmagic/yolov5-s-coco-base/training/model.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "Downloading Chunks for model.pt: 100% 174M/174M [00:03<00:00, 50.4MB/s]\n",
            "Combining Chunks: 100% 174M/174M [00:00<00:00, 651MB/s]\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 567 layers, 86749405 parameters, 0 gradients, 206.3 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/labels/train2017' images and labels...126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<00:00, 5916.65it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/yolov5/yolov5_runs/train/exp/labels.jpg... \n",
            "2025-01-18 20:08:17 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/18-01-2025_20.08.17.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/18-01-2025_20.08.17.log\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mSparse training detected. Wrapping training process with SparseML\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mDisabling LR scheduler, managing LR using SparseML recipe\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOverriding total number of training epochs with value from recipe: 110\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov5/yolov5_runs/train/exp\u001b[0m\n",
            "Starting training for 110 epochs...\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/109      3.98G    0.04431     0.0645     0.0163        227        640: 100% 8/8 [00:08<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.50it/s]\n",
            "                   all        128        929      0.701      0.625      0.713      0.463\n",
            "Adjusted gradient clipping threshold to 2.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/109      4.83G    0.04495    0.05968    0.01734        215        640: 100% 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.71it/s]\n",
            "                   all        128        929      0.774      0.595      0.713      0.468\n",
            "Adjusted gradient clipping threshold to 2.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      2/109      4.83G    0.04314    0.05864    0.01505        192        640: 100% 8/8 [00:01<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.66it/s]\n",
            "                   all        128        929      0.763      0.626      0.743        0.5\n",
            "Adjusted gradient clipping threshold to 5.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      3/109      4.83G    0.04533      0.059    0.01506        198        640: 100% 8/8 [00:01<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.75it/s]\n",
            "                   all        128        929      0.781      0.671      0.764      0.476\n",
            "Adjusted gradient clipping threshold to 5.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      4/109      4.83G    0.04394     0.0549     0.0133        231        640: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.77it/s]\n",
            "                   all        128        929      0.765       0.72      0.797      0.526\n",
            "Adjusted gradient clipping threshold to 5.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      5/109      4.83G    0.04296    0.05951    0.01147        211        640: 100% 8/8 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.79it/s]\n",
            "                   all        128        929      0.788      0.724      0.809      0.543\n",
            "Adjusted gradient clipping threshold to 5.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      6/109      4.84G    0.04296    0.05904     0.0131        205        640: 100% 8/8 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.65it/s]\n",
            "                   all        128        929      0.829      0.709      0.815      0.547\n",
            "Adjusted gradient clipping threshold to 7.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      7/109      4.86G    0.04218    0.06437     0.0127        152        640: 100% 8/8 [00:01<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.815      0.738      0.815      0.556\n",
            "Adjusted gradient clipping threshold to 7.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      8/109      4.88G    0.04269    0.05482    0.01067        228        640: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.79it/s]\n",
            "                   all        128        929      0.771      0.742      0.823      0.545\n",
            "Adjusted gradient clipping threshold to 7.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      9/109       4.9G    0.04181    0.05329    0.01155        142        640: 100% 8/8 [00:01<00:00,  4.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929      0.783      0.733      0.823       0.54\n",
            "Adjusted gradient clipping threshold to 7.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     10/109      4.92G    0.04182    0.05617    0.01079        246        640: 100% 8/8 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.57it/s]\n",
            "                   all        128        929      0.769      0.779      0.824      0.551\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     11/109      4.95G    0.04112    0.05463   0.009941        159        640: 100% 8/8 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.842      0.731      0.838      0.555\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     12/109      4.97G    0.04077    0.05299    0.01118        203        640: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.74it/s]\n",
            "                   all        128        929       0.87      0.743      0.837      0.566\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     13/109      4.97G     0.0403    0.05316   0.008945        217        640: 100% 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.92it/s]\n",
            "                   all        128        929      0.847      0.782      0.855      0.563\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     14/109      4.97G    0.04167    0.05866    0.01003        216        640: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.85it/s]\n",
            "                   all        128        929      0.818      0.786       0.85      0.586\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     15/109      4.97G    0.03903    0.05004   0.008738        198        640: 100% 8/8 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.863      0.784      0.867      0.606\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     16/109      4.97G    0.04182    0.05143   0.008509        239        640: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.886      0.787      0.869      0.589\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     17/109      4.97G    0.03966    0.04867   0.009402        198        640: 100% 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.87it/s]\n",
            "                   all        128        929      0.798      0.798      0.848       0.59\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     18/109      4.97G     0.0402    0.04971   0.009458        260        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.73it/s]\n",
            "                   all        128        929      0.865      0.822      0.873      0.609\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     19/109      4.97G    0.03909    0.04825   0.009428        208        640: 100% 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929      0.858      0.817      0.876      0.603\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     20/109      4.97G    0.04024    0.05227   0.008222        253        640: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.85it/s]\n",
            "                   all        128        929      0.856      0.798      0.882      0.614\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     21/109      4.99G    0.03946     0.0497   0.009595        268        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.856      0.831       0.88      0.605\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     22/109      5.01G    0.03848    0.04518   0.006349        168        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.881      0.795      0.874      0.606\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     23/109      5.03G    0.03807    0.05133   0.008445        233        640: 100% 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.78it/s]\n",
            "                   all        128        929      0.854      0.761      0.841      0.568\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     24/109      5.05G    0.03882    0.04733   0.008045        196        640: 100% 8/8 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.825       0.79      0.859      0.583\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     25/109      5.07G    0.03718    0.04678   0.007827        191        640: 100% 8/8 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.856      0.796      0.873      0.593\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     26/109      5.09G    0.03972    0.05438   0.008202        242        640: 100% 8/8 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.864      0.788      0.883      0.609\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     27/109      5.12G    0.03709    0.05265   0.007322        283        640: 100% 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.72it/s]\n",
            "                   all        128        929      0.864      0.807      0.875      0.607\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     28/109      5.14G    0.03726    0.04932    0.00794        289        640: 100% 8/8 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.858      0.788      0.892      0.617\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     29/109      5.16G    0.03756    0.04751   0.007224        201        640: 100% 8/8 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.877      0.786      0.886      0.629\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     30/109      5.18G    0.03689    0.04423   0.009525        146        640: 100% 8/8 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.873      0.826      0.898      0.632\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     31/109       5.2G    0.03843    0.04854   0.007588        193        640: 100% 8/8 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.67it/s]\n",
            "                   all        128        929       0.88      0.826      0.897      0.642\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     32/109      5.22G    0.03733    0.04788   0.007304        212        640: 100% 8/8 [00:01<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.883      0.833      0.897      0.639\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     33/109      5.24G    0.03812    0.04613   0.008386        191        640: 100% 8/8 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.79it/s]\n",
            "                   all        128        929       0.89      0.817      0.896      0.636\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     34/109      5.26G     0.0381    0.04543   0.007801        184        640: 100% 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.849      0.839      0.895      0.641\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     35/109      5.29G    0.03778    0.05169   0.006817        263        640: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.72it/s]\n",
            "                   all        128        929      0.875      0.824      0.893      0.632\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     36/109      5.31G    0.03858     0.0514   0.008453        301        640: 100% 8/8 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.69it/s]\n",
            "                   all        128        929      0.879      0.828      0.892      0.627\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     37/109      5.31G    0.03677    0.04865   0.006901        229        640: 100% 8/8 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929      0.888      0.831      0.899      0.644\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     38/109      5.31G    0.03707    0.05184    0.00699        214        640: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.855      0.855      0.908       0.65\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     39/109      5.31G    0.03785    0.05079   0.007098        166        640: 100% 8/8 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.68it/s]\n",
            "                   all        128        929      0.887      0.836       0.91      0.653\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     40/109      5.31G    0.03489    0.04535   0.006836        189        640: 100% 8/8 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.69it/s]\n",
            "                   all        128        929      0.896      0.831      0.898      0.658\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     41/109      5.31G    0.03528    0.04922   0.007147        208        640: 100% 8/8 [00:01<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.77it/s]\n",
            "                   all        128        929      0.891      0.846      0.916      0.668\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     42/109      5.31G    0.03496    0.04398   0.007263        257        640: 100% 8/8 [00:01<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.78it/s]\n",
            "                   all        128        929      0.899      0.834      0.904      0.671\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     43/109      5.31G    0.03682    0.04761    0.00626        215        640: 100% 8/8 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.68it/s]\n",
            "                   all        128        929      0.906      0.842      0.919      0.674\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     44/109      5.31G    0.03667    0.04862   0.007528        245        640: 100% 8/8 [00:01<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.74it/s]\n",
            "                   all        128        929      0.902       0.85      0.922      0.678\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     45/109      5.31G    0.03515    0.04115   0.006237        208        640: 100% 8/8 [00:01<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.917      0.842      0.928       0.68\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     46/109      5.31G    0.03529    0.04753    0.00726        256        640: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.84it/s]\n",
            "                   all        128        929      0.918      0.849      0.925      0.681\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     47/109      5.31G    0.03423    0.04425   0.006331        183        640: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.72it/s]\n",
            "                   all        128        929      0.903       0.86      0.928      0.688\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     48/109      5.31G    0.03557    0.04518   0.006489        179        640: 100% 8/8 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.75it/s]\n",
            "                   all        128        929      0.923      0.835       0.92      0.684\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     49/109      5.31G    0.03324    0.04521   0.005974        231        640: 100% 8/8 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.868      0.879      0.928      0.684\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     50/109      5.31G    0.03505     0.0418   0.005705        306        640: 100% 8/8 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.75it/s]\n",
            "                   all        128        929      0.883      0.863      0.926      0.694\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     51/109      5.31G    0.03479     0.0426   0.006586        194        640: 100% 8/8 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.74it/s]\n",
            "                   all        128        929      0.919      0.843      0.922      0.688\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     52/109      5.31G    0.03487     0.0429   0.007432        211        640: 100% 8/8 [00:01<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.63it/s]\n",
            "                   all        128        929      0.911      0.846      0.928      0.696\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     53/109      5.31G     0.0342    0.04457   0.006236        184        640: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.77it/s]\n",
            "                   all        128        929      0.898       0.87      0.934      0.704\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     54/109      5.31G    0.03369    0.03842   0.007057        191        640: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.78it/s]\n",
            "                   all        128        929      0.918      0.865      0.931      0.692\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     55/109      5.31G     0.0335    0.04492   0.005631        267        640: 100% 8/8 [00:01<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929       0.92      0.854      0.934      0.701\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     56/109      5.31G     0.0326    0.04179   0.005251        214        640: 100% 8/8 [00:01<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929       0.93      0.851      0.927      0.701\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     57/109      5.31G    0.03295    0.04014   0.004897        221        640: 100% 8/8 [00:01<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.924      0.853      0.929      0.703\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     58/109      5.31G    0.03501    0.04927    0.00615        247        640: 100% 8/8 [00:01<00:00,  4.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.915      0.848      0.932      0.697\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     59/109      5.31G    0.03291    0.04425   0.006173        221        640: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.78it/s]\n",
            "                   all        128        929       0.92      0.861      0.933      0.694\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     60/109      5.31G    0.03391    0.03832   0.005948        136        640: 100% 8/8 [00:01<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.69it/s]\n",
            "                   all        128        929      0.908       0.87      0.932      0.701\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     61/109      5.31G     0.0336    0.04326   0.006046        290        640: 100% 8/8 [00:01<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.905      0.876      0.934       0.71\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     62/109      5.31G    0.03487    0.04288   0.006141        222        640: 100% 8/8 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.903      0.873       0.94      0.712\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     63/109      5.31G    0.03324    0.04463   0.005724        250        640: 100% 8/8 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.78it/s]\n",
            "                   all        128        929      0.899      0.872      0.938      0.707\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     64/109      5.31G    0.03332     0.0435   0.005953        248        640: 100% 8/8 [00:01<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.70it/s]\n",
            "                   all        128        929      0.893      0.877      0.938      0.721\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     65/109      5.31G     0.0327    0.04014   0.005505        232        640: 100% 8/8 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.889      0.877      0.933      0.704\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     66/109      5.31G    0.03268    0.04163   0.005153        231        640: 100% 8/8 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.79it/s]\n",
            "                   all        128        929      0.898      0.874      0.938       0.71\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     67/109      5.31G    0.03282    0.04291   0.006017        197        640: 100% 8/8 [00:01<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.925      0.866      0.939      0.709\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     68/109      5.31G    0.03283    0.04387   0.005509        205        640: 100% 8/8 [00:01<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.73it/s]\n",
            "                   all        128        929      0.926       0.87      0.941      0.707\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     69/109      5.31G    0.03285     0.0404   0.005499        191        640: 100% 8/8 [00:02<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.921      0.865       0.94      0.717\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     70/109      5.31G    0.03099    0.03902   0.004749        200        640: 100% 8/8 [00:02<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.85it/s]\n",
            "                   all        128        929      0.914      0.866      0.939      0.724\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     71/109      5.31G    0.03044    0.03907   0.004883        218        640: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.916      0.877      0.934      0.725\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     72/109      5.31G    0.03175    0.03883   0.004744        197        640: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.66it/s]\n",
            "                   all        128        929      0.917      0.871       0.93      0.722\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     73/109      5.31G    0.03275    0.04047    0.00518        179        640: 100% 8/8 [00:01<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.71it/s]\n",
            "                   all        128        929      0.914      0.873      0.929      0.731\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     74/109      5.31G    0.03381     0.0425   0.005477        235        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.904      0.885      0.939      0.737\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     75/109      5.31G    0.03168    0.03971   0.005234        241        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.86it/s]\n",
            "                   all        128        929      0.905      0.886      0.933      0.732\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     76/109      5.31G    0.03291    0.03619   0.004873        211        640: 100% 8/8 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.66it/s]\n",
            "                   all        128        929      0.898      0.885      0.932      0.741\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     77/109      5.31G    0.03019    0.03542   0.004275        150        640: 100% 8/8 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.72it/s]\n",
            "                   all        128        929      0.907       0.89      0.942      0.751\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     78/109      5.62G      0.032    0.03883   0.006166        221        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.906      0.887      0.943      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     79/109      5.62G    0.03136    0.04182   0.004796        226        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.85it/s]\n",
            "                   all        128        929      0.914      0.891      0.944      0.747\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     80/109      5.62G    0.03152    0.03646   0.004884        179        640: 100% 8/8 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.74it/s]\n",
            "                   all        128        929      0.908      0.892      0.944      0.746\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     81/109      5.62G    0.03076    0.03613   0.005459        214        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929      0.917      0.877      0.941      0.741\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     82/109      5.62G    0.02869    0.03437   0.004781        182        640: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.911      0.879      0.928      0.744\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     83/109      5.62G    0.02924    0.03286   0.004053        166        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929       0.92      0.873      0.926      0.741\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     84/109      5.62G    0.03374    0.03512   0.005481        222        640: 100% 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.917      0.876      0.928      0.738\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     85/109      5.62G    0.03268    0.03898    0.00507        141        640: 100% 8/8 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.75it/s]\n",
            "                   all        128        929      0.922      0.884      0.932      0.742\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     86/109      5.62G    0.03113    0.03801   0.005509        176        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.924      0.884      0.928      0.746\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     87/109      5.62G    0.03001    0.03574   0.004583        272        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.916      0.885      0.934      0.747\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     88/109      5.62G    0.03032    0.03438   0.004241        111        640: 100% 8/8 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929       0.91      0.885      0.933      0.752\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     89/109      5.62G    0.03142    0.03464   0.004833        183        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.69it/s]\n",
            "                   all        128        929      0.913      0.886      0.934      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     90/109      5.62G    0.03055    0.03719   0.004874        209        640: 100% 8/8 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.71it/s]\n",
            "                   all        128        929      0.917      0.884      0.933       0.76\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     91/109      5.62G    0.02954    0.03548   0.004709        171        640: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.916      0.889      0.934      0.761\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     92/109      5.62G     0.0314    0.03548   0.005009        190        640: 100% 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.84it/s]\n",
            "                   all        128        929      0.906      0.889      0.935      0.757\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     93/109      5.62G    0.03116    0.03822   0.004143        144        640: 100% 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.76it/s]\n",
            "                   all        128        929      0.915      0.891      0.936      0.755\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     94/109      5.62G    0.03176    0.04029   0.004724        210        640: 100% 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.77it/s]\n",
            "                   all        128        929       0.91      0.894      0.935      0.758\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     95/109      5.62G    0.03006    0.03725   0.004086        204        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.83it/s]\n",
            "                   all        128        929      0.911      0.895      0.935      0.758\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     96/109      5.62G    0.02959     0.0356   0.004554        146        640: 100% 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.82it/s]\n",
            "                   all        128        929      0.911      0.896      0.937      0.762\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     97/109      5.62G    0.03186    0.03976   0.004461        219        640: 100% 8/8 [00:01<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.80it/s]\n",
            "                   all        128        929      0.909      0.897      0.935      0.759\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     98/109      5.62G    0.02956    0.03592   0.004144        255        640: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.69it/s]\n",
            "                   all        128        929      0.912      0.895      0.936       0.76\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     99/109      5.62G    0.03093    0.03854   0.004637        246        640: 100% 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:01<00:00,  2.81it/s]\n",
            "                   all        128        929      0.915      0.895      0.938      0.766\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mStarting QAT phase\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mTurning off EMA (not supported with QAT)\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mTurning off AMP (not supported with QAT)\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mBatch size rescaled to 4 with 16.0 gradient accumulation steps for QAT\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    100/109      5.62G    0.03046    0.03705   0.004687         31        640: |          | 32/? [00:10<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:03<00:00,  5.20it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    101/109      5.62G    0.02938    0.03702    0.00425         71        640: |          | 32/? [00:07<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.66it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    102/109      5.62G    0.02829    0.03562   0.003532         27        640: |          | 32/? [00:07<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.71it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    103/109      5.62G    0.03007     0.0414   0.003948         26        640: |          | 32/? [00:07<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.76it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    104/109      5.62G    0.03072     0.0383   0.004005         25        640: |          | 32/? [00:07<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.76it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    105/109      5.62G    0.03001    0.03867     0.0038         34        640: |          | 32/? [00:07<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.60it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    106/109      5.62G    0.02942    0.03779   0.004103         52        640: |          | 32/? [00:07<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.71it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    107/109      5.62G    0.02948    0.03684    0.00351         44        640: |          | 32/? [00:07<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.76it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    108/109      5.62G    0.02776    0.03373   0.003718         69        640: |          | 32/? [00:07<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.68it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "    109/109      5.62G    0.02986    0.03494   0.004295         59        640: |          | 32/? [00:07<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:02<00:00,  5.55it/s]\n",
            "                   all        128        929      0.915       0.89      0.936      0.754\n",
            "\n",
            "110 epochs completed in 0.138 hours.\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOptimizer stripped from /content/yolov5/yolov5_runs/train/exp/weights/best_dense.pt, 14.6MB\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOptimizer stripped from /content/yolov5/yolov5_runs/train/exp/weights/best_pruned.pt, 14.6MB\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOptimizer stripped from /content/yolov5/yolov5_runs/train/exp/weights/last.pt, 15.2MB\n",
            "\n",
            "Validating /content/yolov5/yolov5_runs/train/exp/weights/last.pt...\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mLoading sparsified model\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:05<00:00,  2.81it/s]\n",
            "                   all        128        929      0.927      0.883      0.938      0.757\n",
            "                     0        128        254      0.982      0.845      0.963       0.73\n",
            "                     1        128          6          1      0.661      0.972      0.777\n",
            "                     2        128         46      0.979      0.609      0.772       0.42\n",
            "                     3        128          5       0.94          1      0.995      0.937\n",
            "                     4        128          6      0.897          1      0.995      0.856\n",
            "                     5        128          7      0.949          1      0.995      0.851\n",
            "                     6        128          3      0.912          1      0.995      0.941\n",
            "                     7        128         12      0.984      0.833      0.951      0.749\n",
            "                     8        128          6          1      0.819      0.955      0.729\n",
            "                     9        128         14          1      0.462      0.802      0.432\n",
            "                    11        128          2      0.864          1      0.995      0.895\n",
            "                    13        128          9      0.903      0.778      0.973      0.754\n",
            "                    14        128         16      0.983          1      0.995      0.815\n",
            "                    15        128          4          1        0.9      0.995      0.849\n",
            "                    16        128          9      0.984          1      0.995      0.908\n",
            "                    17        128          2      0.806          1      0.995      0.895\n",
            "                    20        128         17          1       0.93      0.984      0.858\n",
            "                    21        128          1      0.789          1      0.995      0.995\n",
            "                    22        128          4      0.915          1      0.995      0.938\n",
            "                    23        128          9      0.974          1      0.995      0.853\n",
            "                    24        128          6      0.947      0.833      0.839      0.659\n",
            "                    25        128         18      0.973      0.944      0.969       0.78\n",
            "                    26        128         19      0.981      0.684      0.799      0.609\n",
            "                    27        128          7      0.961      0.857       0.86      0.747\n",
            "                    28        128          4      0.924          1      0.995      0.914\n",
            "                    29        128          5      0.901        0.8      0.906       0.74\n",
            "                    30        128          1      0.814          1      0.995      0.697\n",
            "                    31        128          7          1      0.819      0.937      0.698\n",
            "                    32        128          6      0.928      0.667      0.669      0.435\n",
            "                    33        128         10          1      0.947      0.995      0.595\n",
            "                    34        128          4          1      0.721      0.995      0.604\n",
            "                    35        128          7      0.977      0.571       0.65      0.408\n",
            "                    36        128          5      0.943          1      0.995      0.762\n",
            "                    38        128          7      0.679      0.714      0.778      0.556\n",
            "                    39        128         18      0.861      0.722       0.85      0.586\n",
            "                    40        128         16      0.762          1      0.907      0.618\n",
            "                    41        128         36      0.952      0.944      0.964      0.709\n",
            "                    42        128          6      0.971          1      0.995      0.782\n",
            "                    43        128         16      0.978      0.812      0.937      0.588\n",
            "                    44        128         22          1      0.735      0.949       0.62\n",
            "                    45        128         28      0.882      0.786      0.908      0.773\n",
            "                    46        128          1      0.895          1      0.995      0.895\n",
            "                    48        128          2      0.899          1      0.995      0.897\n",
            "                    49        128          4      0.913          1      0.995      0.705\n",
            "                    50        128         11          1      0.905      0.995      0.777\n",
            "                    51        128         24      0.947      0.875      0.949      0.723\n",
            "                    52        128          2      0.857          1      0.995      0.995\n",
            "                    53        128          5      0.951          1      0.995      0.869\n",
            "                    54        128         14      0.972          1      0.995      0.915\n",
            "                    55        128          4       0.89          1      0.995      0.908\n",
            "                    56        128         35          1      0.909      0.993      0.755\n",
            "                    57        128          6      0.908          1      0.995       0.88\n",
            "                    58        128         14      0.969          1      0.995      0.845\n",
            "                    59        128          3      0.878          1      0.995      0.995\n",
            "                    60        128         13      0.899      0.846      0.953       0.74\n",
            "                    61        128          2      0.864          1      0.995      0.897\n",
            "                    62        128          2      0.856          1      0.995      0.895\n",
            "                    63        128          3      0.672      0.667      0.789      0.625\n",
            "                    64        128          2      0.871          1      0.995      0.598\n",
            "                    65        128          8      0.863       0.75      0.807      0.639\n",
            "                    67        128          8      0.976      0.875      0.879       0.57\n",
            "                    68        128          3      0.902          1      0.995      0.861\n",
            "                    69        128          5      0.944          1      0.995      0.885\n",
            "                    71        128          6          1      0.843      0.995      0.706\n",
            "                    72        128          5      0.935          1      0.995      0.917\n",
            "                    73        128         29      0.897        0.6      0.835      0.545\n",
            "                    74        128          9      0.976          1      0.995      0.864\n",
            "                    75        128          2      0.862          1      0.995      0.895\n",
            "                    76        128          1          1          0      0.332      0.133\n",
            "                    77        128         21      0.982          1      0.995      0.835\n",
            "                    79        128          5      0.927          1      0.995      0.901\n",
            "Results saved to \u001b[1m/content/yolov5/yolov5_runs/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export model to onnx format. This export command is used for exporting any model. For eg., currently the base model yolov5s.pt will be exported and then\n",
        "#the performance will be evaluated further. Similarly, to test the performance of other models, replace the directory in the weights with the directory of that model.\n",
        "# After training, the directory of the results is mentioned by the code. For eg., Results saved to /content/yolov5/yolov5_runs/train/exp. Please use the best_pruned.pt\n",
        "# model to test the performance of the trained model.\n",
        "!sparseml.yolov5.export_onnx \\\n",
        "  --weights /content/yolov5/yolov5s.pt\\\n",
        "  --dynamic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m4jM5xEC-pN",
        "outputId": "a4d64b65-4431-4348-86b5-1de259e5683b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: sparseml.yolov5.export_onnx: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the model saved in the onnx format.\n",
        "!python val.py --weights /content/yolov5/DeepSparse_Deployment/model.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3cVFKQ_DCpU",
        "outputId": "30d262e7-940c-47c6-db65-5ebe00ae1dad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=data/coco128.yaml, weights=['/content/yolov5/DeepSparse_Deployment/model.onnx'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v7.0-397-gde62f93c Python-3.11.11 torch-2.1.2+cu121 CPU\n",
            "\n",
            "Loading /content/yolov5/DeepSparse_Deployment/model.onnx for ONNX Runtime inference...\n",
            "Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 128/128 [00:12<00:00, 10.64it/s]\n",
            "                   all        128        929      0.669      0.661      0.712      0.472\n",
            "Speed: 0.3ms pre-process, 82.2ms inference, 3.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size calculation for baseline model (yolov5s.pt). Needs to be stored in the state dict format first.\n",
        "\n",
        "import torch\n",
        "from models.common import Conv\n",
        "from utils.torch_utils import select_device\n",
        "from models.common import DetectMultiBackend\n",
        "import os\n",
        "\n",
        "model = DetectMultiBackend('yolov5s.pt', device='cpu')\n",
        "\n",
        "\n",
        "def get_model_size(model):\n",
        "    temp_path = \"temp_object_detection_model.pth\"\n",
        "    torch.save(model.state_dict(), temp_path)\n",
        "    size_in_mb = os.path.getsize(temp_path) / (1024 * 1024)\n",
        "    os.remove(temp_path)\n",
        "    return size_in_mb\n",
        "\n",
        "model_size = get_model_size(model)\n",
        "print(f'Model Size: {model_size:.2f} MB')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU4trHU_J5-4",
        "outputId": "0c24f2e3-3e94-4998-a410-b877154ae68d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 27.61 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size calculation for compressed model (already stored in state dict form by the library)\n",
        "\n",
        "model = torch.load('/content/yolov5/runs/val/exp/weights/best_pruned.pt', map_location='cpu')\n",
        "\n",
        "\n",
        "def get_model_size(model):\n",
        "    temp_path = \"temp_object_detection_model.pth\"\n",
        "    torch.save(model, temp_path)\n",
        "    size_in_mb = os.path.getsize(temp_path) / (1024 * 1024)\n",
        "    os.remove(temp_path)\n",
        "    return size_in_mb\n",
        "\n",
        "model_size = get_model_size(model)\n",
        "print(f'Model Size: {model_size:.2f} MB')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C_pz_YWKR5y",
        "outputId": "ec6156cc-16d8-4a0a-8f74-a088d1e336f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size: 13.97 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert accuracy and inference time values from the results of model evaluation code (!python val.py....)\n",
        "\n",
        "baseline_accuracy=71.2\n",
        "accuracy=93.5\n",
        "\n",
        "baseline_inference_time=82.2\n",
        "avg_inference_time=80.9\n",
        "\n",
        "# Insert model size results based on above calculations\n",
        "\n",
        "baseline_model_size=27.6\n",
        "model_size=13.97\n",
        "\n",
        "accuracy_drop = baseline_accuracy - accuracy\n",
        "speed_improvement = (baseline_inference_time - avg_inference_time) / baseline_inference_time * 100\n",
        "size_reduction = (baseline_model_size - model_size) / baseline_model_size * 100\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f'Accuracy Drop: {accuracy_drop:.2f}%')\n",
        "print(f'Speed Improvement: {speed_improvement:.2f}%')\n",
        "print(f'Size Reduction: {size_reduction:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MNyOvm1JaRv",
        "outputId": "47eeab34-5a80-4b11-9925-d0d0bf7caada"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Comparison:\n",
            "Accuracy Drop: -22.30%\n",
            "Speed Improvement: 1.58%\n",
            "Size Reduction: 49.38%\n"
          ]
        }
      ]
    }
  ]
}